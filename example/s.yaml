edition: 3.0.0
name: ai-model-app
access: quanxi

resources:
  modelDemo:
    component: fc3@dev
    props:
      region: cn-shanghai
      runtime: custom-container
      functionName: ${env('fc_component_function_name', 'ai-model-test-qwen')}  
      description: model service from functionai test
      logConfig: auto
      vpcConfig: auto
      nasConfig: auto
      instanceConcurrency: 20
      cpu: 8
      memorySize: 65536
      diskSize: 10240
      timeout: 300
      gpuConfig:
        gpuMemorySize: 49152
        gpuType: fc.gpu.ada.1
      customContainerConfig:
        image: >-
          serverless-registry.cn-hangzhou.cr.aliyuncs.com/functionai/dms-vllm:openai_v0.10.0
        port: 9000
        entrypoint:
          - vllm
          - serve 
          - /mnt/${env('fc_component_function_name', 'ai-model-test-qwen')}/${env('MODEL_ID', 'Qwen/Qwen3-32B-AWQ')}
          - --port 
          - "9000" 
          - --served-model-name
          - ${env('MODEL_ID', 'Qwen/Qwen3-32B-AWQ')}
          # - Qwen/Qwen3-14B
          - --tensor-parallel-size 
          - "1"
          - --trust-remote-code  # 添加这个参数
          - --max-model-len
          - "4096" 
      triggers: # 默认，用户可能关注的是开启 authType 是 bear token
        - triggerConfig:
            methods:
              - GET
              - POST
              - PUT
              - DELETE
            authType: anonymous
            disableURLInternet: false
          triggerName: httpTrigger
          description: ''
          qualifier: LATEST
          triggerType: http
      provisionConfig:
        target: 1
        alwaysAllocateCPU: false
        alwaysAllocateGPU: false
        mode: sync

      supplement:
        modelConfig:
          source: modelscope
          id: ${env('MODEL_ID', 'Qwen/Qwen3-32B-AWQ')}
          # id: Qwen/Qwen3-14B
          storage: nas
          role: acs:ram::${config('AccountID')}:role/aliyundevsdefaultrole

